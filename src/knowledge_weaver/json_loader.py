# src/knowledge_weaver/json_loader.py
# Module for loading and consolidating text data from JSON files.

import json
import logging
from pathlib import Path
from typing import List, Dict, Any

def load_processed_texts(processed_text_dir: Path) -> List[Dict[str, Any]]:
    """
    Loads all JSON files from the processed_text directory, consolidates the
    page texts, and returns a list of documents.

    Args:
        processed_text_dir (Path): The directory containing the JSON files
                                   generated by the Data Harvester phase.

    Returns:
        List[Dict[str, Any]]: A list where each dictionary represents a
                              processed PDF document. Each dictionary contains
                              the source filename and the full concatenated text.
    """
    logging.info(f"--- Loading processed text data from: {processed_text_dir} ---")
    documents = []
    json_files = list(processed_text_dir.glob("*.json"))

    if not json_files:
        logging.warning(f"No JSON files found in {processed_text_dir}. Nothing to process.")
        return []

    logging.info(f"Found {len(json_files)} JSON file(s) to load.")

    for json_path in json_files:
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # Concatenate the text from all pages into a single string.
            # We add a separator to maintain some distinction between pages.
            full_text = "\n--- Page Break ---\n".join(
                page.get("extracted_text", "") for page in data.get("pages", [])
            )

            if not full_text.strip():
                logging.warning(f"JSON file '{json_path.name}' contains no extracted text. Skipping.")
                continue

            documents.append({
                "source_filename": data.get("pdf_filename", "unknown_file"),
                "full_text": full_text
            })
            logging.info(f"Successfully loaded and processed '{json_path.name}'.")

        except json.JSONDecodeError:
            logging.error(f"Error decoding JSON from '{json_path.name}'. The file might be corrupt. Skipping.")
        except Exception as e:
            logging.error(f"An unexpected error occurred while processing '{json_path.name}': {e}")

    logging.info(f"--- Finished loading all text data. Total documents: {len(documents)} ---")
    return documents
